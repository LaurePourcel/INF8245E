{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def design_matrix_simple(temperature: np.ndarray, time: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Returns the design matrix [1, temperature]\n",
    "    \n",
    "\n",
    "\n",
    "    Args:\n",
    "        temperature (np.ndarray): Numpy array of shape [observations]\n",
    "        time (np.ndarray): Numpy array of shape [observations]\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Numpy array of shape [observations, 2]\n",
    "    \"\"\"\n",
    "\n",
    "    a = np.ndarray((temperature.shape[0],2))\n",
    "\n",
    "    for k in range (temperature.shape[0]):\n",
    "      a[k,0]=temperature[k]\n",
    "      \n",
    "      a[k,1]=1\n",
    "\n",
    "\n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.testing.assert_allclose(\n",
    "            design_matrix_simple(\n",
    "                np.asarray([22, 23, 35], dtype=np.float64),\n",
    "                np.asarray([0.1, 0.2, 0.3], dtype=np.float64)\n",
    "            ),\n",
    "            np.asarray([[22, 1], [23, 1], [35, 1]]))\n",
    "    Expecting nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.  1.]\n",
      " [23.  1.]\n",
      " [35.  1.]]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "temp = np.asarray([22, 23, 35], dtype=np.float64)\n",
    "time = np.asarray([0.1, 0.2, 0.3])\n",
    "\n",
    "b = design_matrix_simple(temp, time)\n",
    "print(b)\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_predict(X: np.ndarray, w: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Computes $y = Xw$\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Numpy array of shape [observations, features]\n",
    "        -> observations : le nombre de ligne ! features le nombre de chose qu'on va multiplier \n",
    "        w (np.ndarray): Numpy array of shape [features, 1]\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Numpy array of shape [observations, 1]\n",
    "    \"\"\"\n",
    "    \n",
    "    y = np.ndarray((X.shape[0],1))\n",
    "\n",
    "    for k in range(X.shape[0]): # On itère sur le nombre de ligne \n",
    "        for l in range (X.shape[1]):\n",
    "            y[k,0]+= X[k,l]*w[l]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\loulo\\OneDrive\\Bureau\\cours\\INF8245E\\tp\\1.ipynb Cellule 7\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loulo/OneDrive/Bureau/cours/INF8245E/tp/1.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros([\u001b[39m10\u001b[39m, \u001b[39m2\u001b[39m], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loulo/OneDrive/Bureau/cours/INF8245E/tp/1.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m w \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros([\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/loulo/OneDrive/Bureau/cours/INF8245E/tp/1.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m linear_regression_predict(x,w)\n",
      "\u001b[1;32mc:\\Users\\loulo\\OneDrive\\Bureau\\cours\\INF8245E\\tp\\1.ipynb Cellule 7\u001b[0m in \u001b[0;36mlinear_regression_predict\u001b[1;34m(X, w)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loulo/OneDrive/Bureau/cours/INF8245E/tp/1.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlinear_regression_predict\u001b[39m(X: np\u001b[39m.\u001b[39mndarray, w: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loulo/OneDrive/Bureau/cours/INF8245E/tp/1.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\"\"Computes $y = Xw$\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loulo/OneDrive/Bureau/cours/INF8245E/tp/1.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loulo/OneDrive/Bureau/cours/INF8245E/tp/1.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loulo/OneDrive/Bureau/cours/INF8245E/tp/1.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m        np.ndarray: Numpy array of shape [observations, 1]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loulo/OneDrive/Bureau/cours/INF8245E/tp/1.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/loulo/OneDrive/Bureau/cours/INF8245E/tp/1.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mndarray((X\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39m],\u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loulo/OneDrive/Bureau/cours/INF8245E/tp/1.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]): \u001b[39m# On itère sur le nombre de ligne \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/loulo/OneDrive/Bureau/cours/INF8245E/tp/1.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "x = np.zeros([10, 2], dtype=np.float64),\n",
    "w = np.zeros([2, 1], dtype=np.float64)\n",
    "linear_regression_predict(x,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(((y - y_pred) ** 2).mean())\n",
    "\n",
    "def linear_regression_optimize(y: np.ndarray, X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Optimizes MSE fit of $y = Xw$\n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray): Numpy array of shape [observations, 1]\n",
    "        X (np.ndarray): Numpy array of shape [observations, features]\n",
    "        ->on a n lignes pour toutes nos observations et l colonnes pour les features \n",
    "\n",
    "    Returns:\n",
    "        Numpy array of shape [features, 1]\n",
    "\n",
    "        -> on veut w à partir de x et y \n",
    "\n",
    "        tant que MSE baisse on baisse on continue de modifier w \n",
    "\n",
    "        comment on modifie w ? chaque features ? comment on le modifie ? \n",
    "    \"\"\"\n",
    "    X_t = np.transpose(X)\n",
    "    inter_0= np.dot(X_t,X)\n",
    "    inv = np.linalg.inv(inter_0)\n",
    "    inter_1 = np.dot(X_t, y)\n",
    "    w = np.dot(inv,inter_1)\n",
    "    return(w)\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros((15,1))\n",
    "print(type(y))\n",
    "y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_optimize(y: np.ndarray, X: np.ndarray, hyperparameter: float) -> np.ndarray:\n",
    "    X_t = np.transpose(X)\n",
    "    inter_0= np.dot(X_t,X)\n",
    "\n",
    "    Id = np.eye(X.shape[1])\n",
    "    inter_1 = inter_0 + hyperparameter*Id\n",
    "    inter_2 = np.linalg.inv(inter_1)\n",
    "    inter_3 = np.dot(X_t,y)\n",
    "    w = np.dot(inter_2,inter_3)\n",
    "    return(w)\n",
    "    \"\"\"Optimizes MSE fit of $y = Xw$ with L2 regualization\n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray): Numpy array of shape [observations, 1]\n",
    "        X (np.ndarray): Numpy array of shape [observations, features]\n",
    "        hyperparameter (float): Lambda used in L2 regularization\n",
    "\n",
    "    Returns:\n",
    "        Numpy array of shape [features, 1]\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y: np.ndarray, X: np.ndarray, splits=3, seed=0):\n",
    "    \"\"\"Generates cross validation splits \n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray): Numpy array of shape [observations, 1]\n",
    "        X (np.ndarray): Numpy array of shape [observations, features]\n",
    "        splits (int): The number of cross validation splits\n",
    "        seed (int): The random seed used to shuffle the data.\n",
    "\n",
    "    Yields:\n",
    "        Tuple[\n",
    "            Tuple[np.ndarray, np.ndarray],\n",
    "            Tuple[np.ndarray, np.ndarray],\n",
    "        ]: Two (y, X) tuples. First the training split, then the validation split.\n",
    "    \"\"\"\n",
    "    obs = X.shape[0]\n",
    "\n",
    "    # Because the dataset is not iid. wrt. the index,\n",
    "    # it is important to shuffle it\n",
    "    rng = np.random.default_rng(seed)\n",
    "    perm = rng.permutation(obs)\n",
    "    y = y[perm, :]\n",
    "    X = X[perm, :]\n",
    "    fold_1_valid = (y[0: obs/3,:],X[0: obs/3,:])\n",
    "    fold_1 = (y[obs/3 : obs ,:],X[obs/3 : obs ,:])\n",
    "    fold_2_valid = (y[obs/3: 2*obs/3,:],X[obs/3: 2*obs/3,:])\n",
    "\n",
    "    fold_3_valid = (y[2*obs/3 : obs,:],X[2*obs/3: obs,:])\n",
    "    fold_1 = np.concatenate(fold_2_valid, fold_3_valid)\n",
    "    fold_2 = np.concatenate(fold_1_valid, fold_3_valid, fold_3_valid)\n",
    "    print(fold_2)\n",
    "    fold_2 = np.concatenate(fold_1_valid, fold_3_valid)\n",
    "    print(fold_2)\n",
    "    fold_3= np.concatenate(fold_1_valid, fold_2_valid)\n",
    "    L_fold= [fold_1, fold_2, fold_3]\n",
    "    L_valid = [fold_1_valid, fold_2_valid, fold_3_valid]\n",
    "    for split in range(splits):\n",
    "        (y_train, X_train), (y_valid, X_valid)= L_fold[split], L_valid[split]\n",
    "        yield ((y_train, X_train), (y_valid, X_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5.]\n",
      "[0. 1. 2. 3. 4. 5. 0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "x = np.arange(9.0)\n",
    "y = np.arange(9.0)\n",
    "L_x = np.split(x, 3)\n",
    "\n",
    "L_y = np.split(y, 3)\n",
    "#L_x_train= [np.concatenate(L_x[1], L_x[2]), np.concatenate(L_x[0], L_x[2]),np.concatenate(L_x[0], L_x[1])]\n",
    "\n",
    "print(np.concatenate((L_x[0], L_x[1])))\n",
    "print(np.concatenate((L_x[0], L_x[1], L_x[0])))\n",
    "#L_y_train= [np.concatenate(L_y[1], L_y[2]), np.concatenate(L_y[0], L_y[2]),np.concatenate(L_y[0], L_y[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y: np.ndarray, X: np.ndarray, splits=3, seed=0):\n",
    "    \"\"\"Generates cross validation splits \n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray): Numpy array of shape [observations, 1]\n",
    "        X (np.ndarray): Numpy array of shape [observations, features]\n",
    "        splits (int): The number of cross validation splits\n",
    "        seed (int): The random seed used to shuffle the data.\n",
    "\n",
    "    Yields:\n",
    "        Tuple[\n",
    "            Tuple[np.ndarray, np.ndarray],\n",
    "            Tuple[np.ndarray, np.ndarray],\n",
    "        ]: Two (y, X) tuples. First the training split, then the validation split.\n",
    "    \"\"\"\n",
    "    obs = X.shape[0]\n",
    "    \n",
    "\n",
    "    # Because the dataset is not iid. wrt. the index,\n",
    "    # it is important to shuffle it\n",
    "    rng = np.random.default_rng(seed)\n",
    "    perm = rng.permutation(obs)\n",
    "    y = y[perm, :]\n",
    "    X = X[perm, :]\n",
    "\n",
    "    # In case \n",
    "    L_x = np.split(X, splits)\n",
    "    L_y = np.split(y, splits)\n",
    "    L_x_train = L_x\n",
    "    L_y_train = L_y\n",
    "    for k in range (splits): \n",
    "        liste_index = [i for i in range (splits)]\n",
    "        liste_index.remove(k)\n",
    "        inter = L_x [liste_index[0]]\n",
    "        inter2 = L_y [liste_index[0]]\n",
    "        for l in range(1, len(liste_index)):\n",
    "            inter = np.concatenate(inter,L_x[liste_index[l]])\n",
    "            inter2 = np.concatenate(inter,L_y[liste_index[l]])\n",
    "        L_x_train[k]= inter\n",
    "        L_y_train[k]= inter2\n",
    "\n",
    "    for split in range(splits):\n",
    "\n",
    "        (y_train, X_train), (y_valid, X_valid)= (L_y_train[split], L_x_train[split]), (L_y[split], L_x[split])\n",
    "   \n",
    "        yield ((y_train, X_train), (y_valid, X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = cross_validation(np.asarray([[10], [20], [30]]), np.asarray([[11, 12], [21, 22], [31, 32]]), splits=3, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[10, 20, 10, 20, 20]]),\n",
       "  array([[11, 12, 21, 22, 11, 12, 21, 22, 21, 22]])),\n",
       " (array([[10, 20, 10, 20, 20]]),\n",
       "  array([[11, 12, 21, 22, 11, 12, 21, 22, 21, 22]])))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y: np.ndarray, X: np.ndarray, splits=3, seed=0):\n",
    "    \"\"\"Generates cross validation splits \n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray): Numpy array of shape [observations, 1]\n",
    "        X (np.ndarray): Numpy array of shape [observations, features]\n",
    "        splits (int): The number of cross validation splits\n",
    "        seed (int): The random seed used to shuffle the data.\n",
    "\n",
    "    Yields:\n",
    "        Tuple[\n",
    "            Tuple[np.ndarray, np.ndarray],\n",
    "            Tuple[np.ndarray, np.ndarray],\n",
    "        ]: Two (y, X) tuples. First the training split, then the validation split.\n",
    "    \"\"\"\n",
    "    obs = X.shape[0]\n",
    "    \n",
    "\n",
    "    # Because the dataset is not iid. wrt. the index,\n",
    "    # it is important to shuffle it\n",
    "    rng = np.random.default_rng(seed)\n",
    "    perm = rng.permutation(obs)\n",
    "    y = y[perm, :]\n",
    "    X = X[perm, :]\n",
    "\n",
    "    # In case \n",
    "    L_x = np.split(X, splits)\n",
    "    L_y = np.split(y, splits)\n",
    "    L_x_train = L_x\n",
    "    L_y_train = L_y\n",
    "    for k in range (splits): \n",
    "        liste_index = [i for i in range (splits)]\n",
    "        liste_index.remove(k)\n",
    "        inter = L_x [liste_index[0]]\n",
    "        inter2 = L_y [liste_index[0]]\n",
    "        for l in range(1, len(liste_index)):\n",
    "            inter = np.concatenate((inter,L_x[liste_index[l]]), axis=1)\n",
    "            inter2 = np.concatenate((inter2,L_y[liste_index[l]]), axis = 1)\n",
    "        L_x_train[k]= inter\n",
    "        L_y_train[k]= inter2\n",
    "\n",
    "    for split in range(splits):\n",
    "\n",
    "        (y_train, X_train), (y_valid, X_valid)= (L_y_train[split], L_x_train[split]), (L_y[split], L_x[split])\n",
    "\n",
    "        yield ((y_train, X_train), (y_valid, X_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Names Names Names\n",
      "i.     Tom  Mark  Tony\n",
      "ii.    Tom  Mark  Tony\n",
      "iii.   Tom  Mark  Tony\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "my_list = [[ ' Tom', 'Mark', 'Tony' ],[ ' Tom', 'Mark', 'Tony' ],[ ' Tom', 'Mark', 'Tony' ]]\n",
    "df = pd.DataFrame(my_list, index = [ 'i.', 'ii.', 'iii.' ],columns = ['Names','Names','Names'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def ridge_regression_gradient(y: np.ndarray, X: np.ndarray, w: np.ndarray, hyperparameter: float) -> np.ndarray:\n",
    "    \"\"\"Compute the gradient of w with respect to the loss\n",
    "    \n",
    "    Args:\n",
    "        y (np.ndarray): Numpy array of shape [observations, 1]\n",
    "        X (np.ndarray): Numpy array of shape [observations, features]\n",
    "        w (np.ndarray): Numpy array of shape [features, 1], where the last value is w_0 and all other values represent w_1\n",
    "        hyperparameter (float): Lambda used in L2 regularizer\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Gradient of w with respect to the loss, as a numpy array of the same shape as w.\n",
    "    \"\"\"\n",
    "    grad = w\n",
    "    N = X.shape[0]\n",
    "    y_pred = np.dot(X,w)\n",
    "    mean_error = 0\n",
    "    for k in range ( N): \n",
    "        mean_error += y_pred[k]-y[k]\n",
    "    for k in range (w.shape[0]):\n",
    "        x = sqrt(np.dot(X,np.transpose(X)))\n",
    "        grad[k]= (1/N)*mean_error*(x**k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.116]]\n",
      "\n",
      "  [[ 0.856]]\n",
      "\n",
      "  [[-0.562]]]]\n",
      "-0.3\n",
      "[0.48854]\n"
     ]
    }
   ],
   "source": [
    "y = np.asarray([[0.5], [-0.5], [1.4]], dtype=np.float64),\n",
    "X = np.asarray([[-0.3, 0.1], [0.2, 1.1], [-0.45, -0.77]], dtype=np.float64),\n",
    "w = np.asarray([ [-0.12],[0.8]], dtype=np.float64),\n",
    "y_pred = np.dot(X,w)\n",
    "print(y_pred)\n",
    "norme = (0.12**2+0.8**2)**1/2\n",
    "#print(X[0])\n",
    "#print(y_pred)\n",
    "#print(y_pred[0])\n",
    "#print(y_pred[0][1][0][0])\n",
    "print(X[0][0][0])\n",
    "somme = 0 \n",
    "y_pred = np.dot(X,w)\n",
    "for k in range(len(y_pred[0])):\n",
    "    somme += (y_pred[0][k][0][0] - y[0][k])*X[0][k][0]\n",
    "print(somme/3 + 0.2*norme)\n",
    "#print(somme/3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2349559999999995\n"
     ]
    }
   ],
   "source": [
    "X = [[-0.3, 0.1], [0.2, 1.1], [-0.45, -0.77]]\n",
    "w = [-0.12, 0.8 ]\n",
    "somme = 0 \n",
    "for k in range (3): \n",
    "\n",
    "    for i in range(2):\n",
    "        somme += (w[i] * X[k][i])**2\n",
    "print(somme - 1.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*0.12*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.76"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*1.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3552\n"
     ]
    }
   ],
   "source": [
    "somme = -0.12*3 - 0.024\n",
    "X = [0.1, 1.25, 0.7954]\n",
    "X1 = [0.316, 1.11, -0.89]\n",
    "X2 = [-0.3, 0.2, -0.45]\n",
    "for k in range (3): \n",
    "    somme += 0.8 * X1[k]\n",
    "print(somme - 1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0]\n",
      "la diff [-0.384] multiplié [0.1152]\n",
      "la diff [-0.384] multiplié [-0.0384]\n",
      "la diff [1.356] multiplié [0.2712]\n",
      "la diff [1.356] multiplié [1.4916]\n",
      "la diff [-1.962] multiplié [0.8829]\n",
      "la diff [-1.962] multiplié [1.51074]\n",
      "[array([1.2693]), array([2.96394])]\n",
      "[array([0.58488999]), array([1.14976999])]\n"
     ]
    }
   ],
   "source": [
    "X = [[-0.3, 0.1], [0.2, 1.1], [-0.45, -0.77]]\n",
    "w = [ -0.12,0.8 ]\n",
    "y = [[0.5], [-0.5], [1.4]]\n",
    "    ## on constitue les prédictions \n",
    "y_pred = np.dot(X,w)\n",
    "norme = 0 \n",
    "for k in range(len(w)): \n",
    "      norme+= w[k]**2\n",
    "norme = sqrt(norme)\n",
    "Liste = [0 for k in range (len(w))]\n",
    "print(Liste)\n",
    "grad = w \n",
    "for k in range(len(y_pred)):\n",
    "      for i in range(len(Liste)):\n",
    "\n",
    "            Liste[i] += (y_pred[k] - y[k])*X[k][i]\n",
    "            print('la diff', y_pred[k] - y[k], 'multiplié',(y_pred[k] - y[k])*X[k][i])\n",
    "\n",
    "print(Liste)\n",
    "for l in range(len(Liste)): \n",
    "\n",
    "      grad[l]=Liste[l]/3 + 0.2*norme\n",
    "\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def ridge_regression_gradient(y: np.ndarray, X: np.ndarray, w: np.ndarray, hyperparameter: float) -> np.ndarray:\n",
    "    \"\"\"Compute the gradient of w with respect to the loss\n",
    "    \n",
    "    Args:\n",
    "        y (np.ndarray): Numpy array of shape [observations, 1]\n",
    "        X (np.ndarray): Numpy array of shape [observations, features]\n",
    "        w (np.ndarray): Numpy array of shape [features, 1], where the last value is w_0 and all other values represent w_1\n",
    "        hyperparameter (float): Lambda used in L2 regularizer\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Gradient of w with respect to the loss, as a numpy array of the same shape as w.\n",
    "        \"\"\"\n",
    "\n",
    "    ## on constitue les prédictions \n",
    "    y_pred = np.dot(X,w)\n",
    "    norme = 0 \n",
    "    for k in range(len(w)): \n",
    "          norme+= w[k]**2\n",
    "    norme = sqrt(norme)\n",
    "    Liste = [0 for k in range (len(w))]\n",
    "\n",
    "    grad = w \n",
    "    for k in range(len(y_pred)):\n",
    "          for i in range(len(Liste)):\n",
    "\n",
    "                Liste[i] += (y_pred[k] - y[k])*X[k][i]\n",
    "\n",
    "\n",
    "    for l in range(len(Liste)): \n",
    "\n",
    "          grad[l]=Liste[l]/3 + 2*hyperparameter*w[l]\n",
    "\n",
    "\n",
    "    return(grad)\n",
    "\n",
    "def ridge_regression_gradient_descent(y_train: np.ndarray, X_train: np.ndarray,\n",
    "                                      y_val: np.ndarray, X_val: np.ndarray,\n",
    "                                      w_init: np.ndarray, hyperparameter: float,\n",
    "                                      learning_rate: float, num_steps: int) -> np.ndarray:\n",
    "    \"\"\" Runs gradient descent to optimize the parameters w.\n",
    "    \n",
    "    Args:\n",
    "        y_train (np.ndarray): Numpy array of shape [observations, 1]\n",
    "        X_train (np.ndarray): Numpy array of shape [observations, features]\n",
    "        y_val (np.ndarray): Numpy array of shape [observations, 1]\n",
    "        X_val (np.ndarray): Numpy array of shape [observations, features]\n",
    "        w_init (np.ndarray): Numpy array of shape [features, 1]\n",
    "        hyperparameter (float): Lambda used in L2 regularizer\n",
    "        learning_rate (float): Value to multiply our gradient with before updating our parameters.\n",
    "        num_steps (int): Number of gradient descent steps to perform.\n",
    "    \n",
    "    Returns:\n",
    "        train_loss (np.ndarray): The train RMSE loss without L2 regularizer, for each step.\n",
    "        val_loss (np.ndarray): The validation RMSE loss without L2 regularizer, for each step.\n",
    "        optimized_w (np.ndarray): The optimized w parameters.\n",
    "    \"\"\"\n",
    "    train_losses = np.zeros((num_steps,), dtype=np.float32)  # You will need to update this\n",
    "    val_losses = np.zeros((num_steps,), dtype=np.float32)  # You will need to update this\n",
    "    w_sol = np.copy(w_init)  # You will need to update this\n",
    "    print(w_init)\n",
    "    w = w_init\n",
    "    X = np.concatenate((X_train, X_val))\n",
    "    y = np.concatenate((y_train, y_val))\n",
    "\n",
    "    if num_steps > 1 : \n",
    "        for k in range (num_steps):\n",
    "            #train_losses[k] = rmse (linear_regression_predict(X_train,w_sol), y_train)\n",
    "            #val_losses[k] = rmse (linear_regression_predict(X_val,w_sol), y_val)\n",
    "            grad = ridge_regression_gradient(y_train,X_train,w_sol,hyperparameter)\n",
    "            w = w - grad*learning_rate\n",
    "    \n",
    "    else : \n",
    "            #train_losses[k] = rmse (linear_regression_predict(X_train,w_sol), y_train)\n",
    "            #val_losses[k] = rmse (linear_regression_predict(X_val,w_sol), y_val)\n",
    "            grad = ridge_regression_gradient(y_train,X_train,w_sol,hyperparameter)\n",
    "            w = w_init - grad*learning_rate\n",
    "    ...\n",
    "\n",
    "    return (train_losses, val_losses, w_init - grad*learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = [1.80054, 0.380551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8 ]\n",
      " [-0.12]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.], dtype=float32),\n",
       " array([0.], dtype=float32),\n",
       " array([[ 0.79819946],\n",
       "        [-0.12038055]]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regression_gradient_descent(np.array(([[0.5], [-0.5], [1.4]])) ,np.array(([[-0.3, 0.1], [0.2, 1.1], [-0.45, -0.77]])) ,np.array(([[0.76], [0.13], [-0.82]])) ,np.array(([[1.04, -0.4], [0.9, 0.1], [-0.5, 0.47]])) ,np.asarray(([[0.8], [-0.12]])) ,0.90,1e-3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " array([[ 0.79619808],\n",
    "        [-0.12176295]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "174c9b7f671336d0b03fb6a4f6fd2215b1a4f0beaa17119d68f2e3366192539c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
